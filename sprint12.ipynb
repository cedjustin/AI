{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled1.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyODzawX1/RZHimLRkqtAAo3"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "MJHch2IvnS4-"
      },
      "source": [
        "# importing dependencies\n",
        "import numpy as np\n",
        "from keras.datasets import mnist\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import recall_score\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8b9JjncAnnEz",
        "outputId": "2bb6b14c-5d76-410f-d6c9-a991e20b80bb"
      },
      "source": [
        "# preparation of the data\n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
        "\n",
        "X_train = X_train.reshape(-1, 784)\n",
        "X_test = X_test.reshape(-1, 784)\n",
        "\n",
        "\n",
        "X_train = X_train.astype(np.float)\n",
        "X_test = X_test.astype(np.float)\n",
        "X_train /= 255\n",
        "X_test /= 255\n",
        "\n",
        "enc = OneHotEncoder(handle_unknown='ignore', sparse=False)\n",
        "y_train_one_hot = enc.fit_transform(y_train[:, np.newaxis])\n",
        "y_test_one_hot = enc.transform(y_test[:, np.newaxis])\n",
        "print(y_train.shape) \n",
        "print(y_train_one_hot.shape) \n",
        "print(y_train_one_hot.dtype) "
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(60000,)\n",
            "(60000, 10)\n",
            "float64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DuapwKNcnzzQ",
        "outputId": "71b39510-08cb-4b66-ace2-16fe79a6ebb4"
      },
      "source": [
        "X_train_, X_val, y_train_, y_val = train_test_split(X_train, y_train_one_hot, test_size=0.2)\n",
        "print(\"X_train--->\", X_train_.shape) \n",
        "print(\"X_val--->\", X_val.shape)  \n",
        "print(\"y_train--->\", y_train_.shape) \n",
        "print(\"y_val--->\", y_val.shape)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "X_train---> (48000, 784)\n",
            "X_val---> (12000, 784)\n",
            "y_train---> (48000, 10)\n",
            "y_val---> (12000, 10)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "63qBDZILn-B2"
      },
      "source": [
        "class GetMiniBatch:\n",
        "\n",
        "    def __init__(self, X, y, batch_size = 20, seed=0):\n",
        "        self.batch_size = batch_size\n",
        "        np.random.seed(seed)\n",
        "        shuffle_index = np.random.permutation(np.arange(X.shape[0]))\n",
        "        self._X = X[shuffle_index]\n",
        "        self._y = y[shuffle_index]\n",
        "        self._stop = np.ceil(X.shape[0]/self.batch_size).astype(np.int)\n",
        "\n",
        "    def __len__(self):\n",
        "        return self._stop\n",
        "\n",
        "    def __getitem__(self,item):\n",
        "        p0 = item*self.batch_size\n",
        "        p1 = item*self.batch_size + self.batch_size\n",
        "        return self._X[p0:p1], self._y[p0:p1]        \n",
        "\n",
        "    def __iter__(self):\n",
        "        self._counter = 0\n",
        "        return self\n",
        "\n",
        "    def __next__(self):\n",
        "        if self._counter >= self._stop:\n",
        "            raise StopIteration()\n",
        "        p0 = self._counter*self.batch_size\n",
        "        p1 = self._counter*self.batch_size + self.batch_size\n",
        "        self._counter += 1\n",
        "        return self._X[p0:p1], self._y[p0:p1]\n",
        "\n",
        "get_mini_batch = GetMiniBatch(X_train, y_train_one_hot, batch_size=20)\n",
        "for mini_X_train, mini_y_train in get_mini_batch:\n",
        "    mini_X_train, mini_y_train\n",
        "mini_X_train = mini_X_train.reshape(20, 1, 28, 28)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G-ItDfjaoEjr"
      },
      "source": [
        "class SimpleInitializer:\n",
        "    \n",
        "    def __init__(self, sigma=0.01):\n",
        "        self.sigma = sigma\n",
        "        \n",
        "    def W(self,f_num, Chanel, f_size_h, f_size_w):\n",
        "        np.random.seed(0)\n",
        "        self.W = self.sigma * np.random.randn(f_num, Chanel, f_size_h, f_size_w)\n",
        "        return self.W\n",
        "    \n",
        "    def B(self, f_num):\n",
        "        np.random.seed(0)\n",
        "        self.B = self.sigma * np.random.randn(f_num,1)\n",
        "        return self.B\n",
        "\n",
        "class XavierInitializer:\n",
        "    \n",
        "    def __init__(self, sigma = 0.01):\n",
        "        self.sigma = sigma\n",
        "        \n",
        "    def W(self,f_num, Chanel, f_size_h, f_size_w):\n",
        "        self.sigma = (1 / np.sqrt(f_num))\n",
        "        np.random.seed(0)\n",
        "        self.W = self.sigma * np.random.randn(f_num, Chanel, f_size_h, f_size_w)\n",
        "        return self.W\n",
        "        \n",
        "    def B(self,f_num):\n",
        "        np.random.seed(0)\n",
        "        self.sigma = (1 / np.sqrt(f_num))\n",
        "        self.B = self.sigma * np.random.randn(f_num,1)\n",
        "        return self.B\n",
        "\n",
        "class He:\n",
        "    \n",
        "    def __init__(self, sigma = 0.01):\n",
        "        self.sigma = sigma\n",
        "    \n",
        "    def W(self, f_num, Chanel, f_size_h, f_size_w):\n",
        "        sigma = np.sqrt(2 / 1)\n",
        "        np.random.seed(0)\n",
        "        self.W = sigma * np.random.randn(f_num, Chanel, f_size_h, f_size_w)\n",
        "        return self.W\n",
        "        \n",
        "    def B(self,f_num):\n",
        "        sigma = np.sqrt(2 / 1)\n",
        "        np.random.seed(0)\n",
        "        self.B = sigma * np.random.randn(f_num,1)\n",
        "        return self.B\n",
        "\n",
        "class SGD:\n",
        "\n",
        "    def __init__(self, lr=0.001):\n",
        "        self.lr = lr\n",
        "        \n",
        "    def update(self,layer):\n",
        "\n",
        "        layer.W -= (self.lr * layer.dW)\n",
        "        layer.B -= (self.lr * layer.dB)\n",
        "        return layer.W, layer.B"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_i9lRH3BoKQX"
      },
      "source": [
        "def output_heigh_calculation(X_h,pad_n,F_h,stride):\n",
        "    output_h = (X_h + 2*pad_n - F_h)//stride + 1\n",
        "    return output_h"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cf_7yrNWoONs"
      },
      "source": [
        "def output_width_calculation(X_w,pad_n,F_w,stride):\n",
        "    output_w = (X_w + 2*pad_n - F_w)//stride + 1\n",
        "    return output_w"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RiaLeIw-oO1u"
      },
      "source": [
        "def im2col(input_data, filter_h, filter_w, stride=1, pad=0):\n",
        "    N, C, H, W = input_data.shape\n",
        "    out_h = output_heigh_calculation(X_h=H,pad_n=pad, F_h=filter_h, stride=stride)\n",
        "    out_w = output_width_calculation(X_w=W,pad_n=pad, F_w=filter_w, stride=stride)\n",
        "    img = np.pad(input_data, [(0,0), (0,0), (pad, pad), (pad, pad)], 'constant')\n",
        "    col = np.zeros((N, C, filter_h, filter_w, out_h, out_w))\n",
        "\n",
        "    for y in range(filter_h):\n",
        "        y_max = y + stride*out_h\n",
        "        for x in range(filter_w):\n",
        "            x_max = x + stride*out_w\n",
        "            col[:, :, y, x, :, :] = img[:, :, y:y_max:stride, x:x_max:stride]\n",
        "\n",
        "    col = col.transpose(0, 4, 5, 1, 2, 3).reshape(N*out_h*out_w, -1)\n",
        "    return col"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wP4jhjeBoRga"
      },
      "source": [
        "def col2im(col, X, filter_h, filter_w, stride=1, pad=0):\n",
        "    N, C, H, W = X.shape\n",
        "    out_h = output_heigh_calculation(X_h=H,pad_n=pad, F_h=filter_h, stride=stride)\n",
        "    out_w = output_width_calculation(X_w=W,pad_n=pad, F_w=filter_w, stride=stride)\n",
        "    col = col.reshape(N, out_h, out_w, C, filter_h, filter_w).transpose(0, 3, 4, 5, 1, 2)\n",
        "\n",
        "    img = np.zeros((N, C, H + 2*pad + stride - 1, W + 2*pad + stride - 1))\n",
        "    for y in range(filter_h):\n",
        "        y_max = y + stride*out_h\n",
        "        for x in range(filter_w):\n",
        "            x_max = x + stride*out_w\n",
        "            img[:, :, y:y_max:stride, x:x_max:stride] += col[:, :, y, x, :, :]\n",
        "\n",
        "    return img[:, :, pad:H + pad, pad:W + pad]"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "889vyj5yn87l"
      },
      "source": [
        "【Problem 1】Creating a 2-D convolutional layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DNOJBf0KoZ-S"
      },
      "source": [
        "class SimpleConv2d:\n",
        "    \n",
        "    def __init__(self, f_num=1, f_size_h=2, f_size_w=2, stride=1, pad = 1, initializer=XavierInitializer(), optimizer=SGD(lr=0.05)):\n",
        "\n",
        "        self.f_num = f_num\n",
        "        self.f_size_h = f_size_h\n",
        "        self.f_size_w = f_size_w\n",
        "        self.pad = pad\n",
        "        self.stride = stride\n",
        "        self.kernel  = None\n",
        "        self.initializer = initializer\n",
        "        self.optimizer = optimizer\n",
        "        self.W = None\n",
        "        self.B = None \n",
        "        \n",
        "    def im2col(self, input_data):\n",
        "        N, C, H, W = input_data.shape\n",
        "        out_h = output_heigh_calculation(X_h=H,pad_n=self.pad, F_h= self.f_size_h, stride=self.stride)\n",
        "        out_w = output_width_calculation(X_w=W,pad_n=self.pad, F_w=self.f_size_w, stride=self.stride)\n",
        "        img = np.pad(input_data, [(0,0), (0,0), (self.pad, self.pad), (self.pad, self.pad)], 'constant')\n",
        "        col = np.zeros((N, C, self.f_size_h, self.f_size_w, out_h, out_w))\n",
        "\n",
        "        for y in range(self.f_size_h):\n",
        "            y_max = y + self.stride*out_h\n",
        "            for x in range(self.f_size_w):\n",
        "                x_max = x + self.stride*out_w\n",
        "                col[:, :, y, x, :, :] = img[:, :, y:y_max:self.stride, x:x_max:self.stride]\n",
        "\n",
        "        col = col.transpose(0, 4, 5, 1, 2, 3).reshape(N*out_h*out_w, -1)\n",
        "        return col\n",
        "    \n",
        "    def col2im(self, col, X):\n",
        "        N, C, H, W = X.shape\n",
        "        out_h = output_heigh_calculation(X_h=H,pad_n=self.pad, F_h=self.f_size_h, stride=self.stride)\n",
        "        out_w = output_width_calculation(X_w=W,pad_n=self.pad, F_w=self.f_size_w, stride=self.stride)\n",
        "        col = col.reshape(N, out_h, out_w, C, self.f_size_h, self.f_size_w).transpose(0, 3, 4, 5, 1, 2)\n",
        "        img = np.zeros((N, C, H + 2*self.pad + self.stride - 1, W + 2*self.pad + self.stride - 1))\n",
        "        \n",
        "        for y in range(self.f_size_h):\n",
        "            y_max = y + self.stride*out_h\n",
        "            for x in range(self.f_size_w):\n",
        "                x_max = x + self.stride*out_w\n",
        "                img[:, :, y:y_max:self.stride, x:x_max:self.stride] += col[:, :, y, x, :, :]\n",
        "        return img[:, :, self.pad:H + self.pad, self.pad:W + self.pad]\n",
        "        \n",
        "    def forward(self,X):\n",
        "        if self.W is None:\n",
        "            self.W = self.initializer.W(self.f_num, X.shape[1], self.f_size_h , self.f_size_w)\n",
        "        if self.B is None:\n",
        "            self.B = self.initializer.B(self.f_num)\n",
        "        FN, C, FH, FW = self.W.shape\n",
        "        N, C, H, W = X.shape\n",
        "        out_h = output_heigh_calculation(X_h=H,pad_n=self.pad, F_h=self.f_size_h, stride=self.stride)\n",
        "        out_w = output_width_calculation(X_w=W,pad_n=self.pad, F_w=self.f_size_w, stride=self.stride)\n",
        "            \n",
        "        self.col = self.im2col(X)\n",
        "        self.col_W = self.W.reshape(FN, -1).T\n",
        "        out = np.dot(self.col, self.col_W) + self.B.T\n",
        "        out = out.reshape(N, out_h, out_w, -1).transpose(0,3,1,2)\n",
        "        self.X = X\n",
        "        return out\n",
        "    \n",
        "    def backward(self,dout):\n",
        "        FN, C, FH, FW = self.W.shape\n",
        "        dout = dout.transpose(0,2,3,1).reshape(-1, FN)\n",
        "        self.dB = np.sum(dout, axis=0).reshape(self.f_num,1)\n",
        "        self.dW = np.dot(self.col.T, dout)\n",
        "        self.dW = self.dW.transpose(1, 0).reshape(FN, C, FH, FW)\n",
        "\n",
        "        dcol = np.dot(dout, self.col_W.T)\n",
        "        self.dx = self.col2im(dcol,self.X)\n",
        "        \n",
        "        return self.dx\n",
        "        self = self.optimizer.update(self)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eUcIp_87ofAe"
      },
      "source": [
        "model_test = SimpleConv2d(f_num=3, f_size_h=3,  f_size_w=3, stride=1, pad=1, initializer=SimpleInitializer())"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u_-f-jpIpPgP"
      },
      "source": [
        "【Problem 2】Experiment of 2D convolvolation layer in small array"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DgIl9FGWpIIs"
      },
      "source": [
        "forward_testing = model_test.forward(mini_X_train)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ihr2_xBbogog",
        "outputId": "1a4f8d32-dc1f-4bea-ca17-859adaa95655"
      },
      "source": [
        "model_test.backward(forward_testing)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[[1.25967230e-03, 1.01337586e-03, 1.01337586e-03, ...,\n",
              "          1.01337586e-03, 1.01337586e-03, 1.65385372e-04],\n",
              "         [1.55351675e-03, 1.28528097e-03, 1.28528097e-03, ...,\n",
              "          1.28528097e-03, 1.28528097e-03, 3.41881849e-05],\n",
              "         [1.55351675e-03, 1.28528097e-03, 1.28528097e-03, ...,\n",
              "          1.28528097e-03, 1.28528097e-03, 3.41881849e-05],\n",
              "         ...,\n",
              "         [1.55351675e-03, 1.28528097e-03, 1.28528097e-03, ...,\n",
              "          1.28528097e-03, 1.28528097e-03, 3.41881849e-05],\n",
              "         [1.55351675e-03, 1.28528097e-03, 1.28528097e-03, ...,\n",
              "          1.28528097e-03, 1.28528097e-03, 3.41881849e-05],\n",
              "         [1.20249692e-03, 9.53283644e-04, 9.53283644e-04, ...,\n",
              "          9.53283644e-04, 9.53283644e-04, 6.04504498e-05]]],\n",
              "\n",
              "\n",
              "       [[[1.25967230e-03, 1.01337586e-03, 1.01337586e-03, ...,\n",
              "          1.01337586e-03, 1.01337586e-03, 1.65385372e-04],\n",
              "         [1.55351675e-03, 1.28528097e-03, 1.28528097e-03, ...,\n",
              "          1.28528097e-03, 1.28528097e-03, 3.41881849e-05],\n",
              "         [1.55351675e-03, 1.28528097e-03, 1.28528097e-03, ...,\n",
              "          1.28528097e-03, 1.28528097e-03, 3.41881849e-05],\n",
              "         ...,\n",
              "         [1.55351675e-03, 1.28528097e-03, 1.28528097e-03, ...,\n",
              "          1.28528097e-03, 1.28528097e-03, 3.41881849e-05],\n",
              "         [1.55351675e-03, 1.28528097e-03, 1.28528097e-03, ...,\n",
              "          1.28528097e-03, 1.28528097e-03, 3.41881849e-05],\n",
              "         [1.20249692e-03, 9.53283644e-04, 9.53283644e-04, ...,\n",
              "          9.53283644e-04, 9.53283644e-04, 6.04504498e-05]]],\n",
              "\n",
              "\n",
              "       [[[1.25967230e-03, 1.01337586e-03, 1.01337586e-03, ...,\n",
              "          1.01337586e-03, 1.01337586e-03, 1.65385372e-04],\n",
              "         [1.55351675e-03, 1.28528097e-03, 1.28528097e-03, ...,\n",
              "          1.28528097e-03, 1.28528097e-03, 3.41881849e-05],\n",
              "         [1.55351675e-03, 1.28528097e-03, 1.28528097e-03, ...,\n",
              "          1.28528097e-03, 1.28528097e-03, 3.41881849e-05],\n",
              "         ...,\n",
              "         [1.55351675e-03, 1.28528097e-03, 1.28528097e-03, ...,\n",
              "          1.28528097e-03, 1.28528097e-03, 3.41881849e-05],\n",
              "         [1.55351675e-03, 1.28528097e-03, 1.28528097e-03, ...,\n",
              "          1.28528097e-03, 1.28528097e-03, 3.41881849e-05],\n",
              "         [1.20249692e-03, 9.53283644e-04, 9.53283644e-04, ...,\n",
              "          9.53283644e-04, 9.53283644e-04, 6.04504498e-05]]],\n",
              "\n",
              "\n",
              "       ...,\n",
              "\n",
              "\n",
              "       [[[1.25967230e-03, 1.01337586e-03, 1.01337586e-03, ...,\n",
              "          1.01337586e-03, 1.01337586e-03, 1.65385372e-04],\n",
              "         [1.55351675e-03, 1.28528097e-03, 1.28528097e-03, ...,\n",
              "          1.28528097e-03, 1.28528097e-03, 3.41881849e-05],\n",
              "         [1.55351675e-03, 1.28528097e-03, 1.28528097e-03, ...,\n",
              "          1.28528097e-03, 1.28528097e-03, 3.41881849e-05],\n",
              "         ...,\n",
              "         [1.55351675e-03, 1.28528097e-03, 1.28528097e-03, ...,\n",
              "          1.28528097e-03, 1.28528097e-03, 3.41881849e-05],\n",
              "         [1.55351675e-03, 1.28528097e-03, 1.28528097e-03, ...,\n",
              "          1.28528097e-03, 1.28528097e-03, 3.41881849e-05],\n",
              "         [1.20249692e-03, 9.53283644e-04, 9.53283644e-04, ...,\n",
              "          9.53283644e-04, 9.53283644e-04, 6.04504498e-05]]],\n",
              "\n",
              "\n",
              "       [[[1.25967230e-03, 1.01337586e-03, 1.01337586e-03, ...,\n",
              "          1.01337586e-03, 1.01337586e-03, 1.65385372e-04],\n",
              "         [1.55351675e-03, 1.28528097e-03, 1.28528097e-03, ...,\n",
              "          1.28528097e-03, 1.28528097e-03, 3.41881849e-05],\n",
              "         [1.55351675e-03, 1.28528097e-03, 1.28528097e-03, ...,\n",
              "          1.28528097e-03, 1.28528097e-03, 3.41881849e-05],\n",
              "         ...,\n",
              "         [1.55351675e-03, 1.28528097e-03, 1.28528097e-03, ...,\n",
              "          1.28528097e-03, 1.28528097e-03, 3.41881849e-05],\n",
              "         [1.55351675e-03, 1.28528097e-03, 1.28528097e-03, ...,\n",
              "          1.28528097e-03, 1.28528097e-03, 3.41881849e-05],\n",
              "         [1.20249692e-03, 9.53283644e-04, 9.53283644e-04, ...,\n",
              "          9.53283644e-04, 9.53283644e-04, 6.04504498e-05]]],\n",
              "\n",
              "\n",
              "       [[[1.25967230e-03, 1.01337586e-03, 1.01337586e-03, ...,\n",
              "          1.01337586e-03, 1.01337586e-03, 1.65385372e-04],\n",
              "         [1.55351675e-03, 1.28528097e-03, 1.28528097e-03, ...,\n",
              "          1.28528097e-03, 1.28528097e-03, 3.41881849e-05],\n",
              "         [1.55351675e-03, 1.28528097e-03, 1.28528097e-03, ...,\n",
              "          1.28528097e-03, 1.28528097e-03, 3.41881849e-05],\n",
              "         ...,\n",
              "         [1.55351675e-03, 1.28528097e-03, 1.28528097e-03, ...,\n",
              "          1.28528097e-03, 1.28528097e-03, 3.41881849e-05],\n",
              "         [1.55351675e-03, 1.28528097e-03, 1.28528097e-03, ...,\n",
              "          1.28528097e-03, 1.28528097e-03, 3.41881849e-05],\n",
              "         [1.20249692e-03, 9.53283644e-04, 9.53283644e-04, ...,\n",
              "          9.53283644e-04, 9.53283644e-04, 6.04504498e-05]]]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kcXMa0r-p02e"
      },
      "source": [
        "【Problem 3】"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m2Lvj638oufu",
        "outputId": "1d550676-a837-4355-c3b3-8bbf655ae921"
      },
      "source": [
        "model_test.backward(forward_testing).shape"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(20, 1, 28, 28)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f1ys_JNopZTa"
      },
      "source": [
        "【Problem 4】Create the maximum pooling layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7MOKXZeApX8z"
      },
      "source": [
        "class MaxPool2D:\n",
        "    \n",
        "    def __init__(self, P_h, P_w, stride=1, pad=0):\n",
        "        self.P_h = P_h\n",
        "        self.P_w = P_w\n",
        "        self.stride = stride\n",
        "        self.pad = pad\n",
        "        self.x = None\n",
        "        self.arg_max = None\n",
        "        \n",
        "    def im2col(self, input_data):\n",
        "        N, C, H, W = input_data.shape\n",
        "        out_h = output_heigh_calculation(X_h=H,pad_n=self.pad, F_h= self.P_h, stride=self.stride)\n",
        "        out_w = output_width_calculation(X_w=W,pad_n=self.pad, F_w=self.P_w, stride=self.stride)\n",
        "        img = np.pad(input_data, [(0,0), (0,0), (self.pad, self.pad), (self.pad, self.pad)], 'constant')\n",
        "        col = np.zeros((N, C, self.P_h, self.P_w, out_h, out_w))\n",
        "\n",
        "        for y in range(self.P_h):\n",
        "            y_max = y + self.stride*out_h\n",
        "            for x in range(self.P_w):\n",
        "                x_max = x + self.stride*out_w\n",
        "                col[:, :, y, x, :, :] = img[:, :, y:y_max:self.stride, x:x_max:self.stride]\n",
        "\n",
        "        col = col.transpose(0, 4, 5, 1, 2, 3).reshape(N*out_h*out_w, -1)\n",
        "        return col\n",
        "    \n",
        "    def col2im(self, col, X):\n",
        "        N, C, H, W = X.shape\n",
        "        out_h = output_heigh_calculation(X_h=H,pad_n=self.pad, F_h=self.P_h, stride=self.stride)\n",
        "        out_w = output_width_calculation(X_w=W,pad_n=self.pad, F_w=self.P_w, stride=self.stride)\n",
        "        col = col.reshape(N, out_h, out_w, C, self.P_h, self.P_w).transpose(0, 3, 4, 5, 1, 2)\n",
        "        img = np.zeros((N, C, H + 2*self.pad + self.stride - 1, W + 2*self.pad + self.stride - 1))\n",
        "        \n",
        "        for y in range(self.P_h):\n",
        "            y_max = y + self.stride*out_h\n",
        "            for x in range(self.P_w):\n",
        "                x_max = x + self.stride*out_w\n",
        "                img[:, :, y:y_max:self.stride, x:x_max:self.stride] += col[:, :, y, x, :, :]\n",
        "        return img[:, :, self.pad:H + self.pad, self.pad:W + self.pad]\n",
        "       \n",
        "    def forward(self, x):\n",
        "        N, C, H, W = x.shape\n",
        "        out_h = output_heigh_calculation(X_h=H,pad_n=self.pad, F_h=self.P_h, stride=self.stride)\n",
        "        out_w = output_width_calculation(X_w=W,pad_n=self.pad, F_w=self.P_w, stride=self.stride)\n",
        "        col = self.im2col(x)     \n",
        "        col = col.reshape(-1, self.P_h*self.P_w)\n",
        "        arg_max = np.argmax(col, axis=1)\n",
        "        out = np.max(col, axis=1)\n",
        "        out = out.reshape(N, out_h, out_w, C).transpose(0, 3, 1, 2)\n",
        "        self.x = x\n",
        "        self.arg_max = arg_max\n",
        "        return out\n",
        "\n",
        "    def backward(self, dout):\n",
        "        dout = dout.transpose(0, 2, 3, 1)    \n",
        "        p_size = self.P_h * self.P_w\n",
        "        dmax = np.zeros((dout.size, p_size))\n",
        "        dmax[np.arange(self.arg_max.size), self.arg_max.flatten()] = dout.flatten()\n",
        "        dmax = dmax.reshape(dout.shape + (p_size,))     \n",
        "        dcol = dmax.reshape(dmax.shape[0] * dmax.shape[1] * dmax.shape[2], -1)\n",
        "        dx = self.col2im(dcol, self.x)\n",
        "        return dx\n",
        "        self = self.optimizer.update(self)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JeYUcbviqBB-"
      },
      "source": [
        "test2 = MaxPool2D( P_h=2, P_w=2, stride=2, pad=0)\n",
        "testing2 = test2.forward(forward_testing)\n",
        "testing2backward = test2.backward(testing2)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UcOcgqOwqDYJ",
        "outputId": "8aefdaed-6517-461f-8f94-ac58f73cb4e7"
      },
      "source": [
        "testing2.shape"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(20, 3, 14, 14)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8NTNMfFpqE6C",
        "outputId": "53d24c5a-ed81-4af8-8aac-124af9738b7b"
      },
      "source": [
        "testing2backward.shape"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(20, 3, 28, 28)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rv965_AoqcgJ"
      },
      "source": [
        "[Problem 5] (Advanced Assignment) Creating Average Pooling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EOXe8_7sqZKi"
      },
      "source": [
        "class Flatten:\n",
        "\n",
        "    def forward(self, x):\n",
        "        N, C, H, W = x.shape\n",
        "        out = x.reshape(N, -1)        \n",
        "        self.x = x        \n",
        "        return out\n",
        "    \n",
        "    def backward(self, dout):\n",
        "        dx = dout.reshape(self.x.shape)      \n",
        "        return dx"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L7FBG5pxqjAD",
        "outputId": "68d7c9de-ef24-4927-aaab-e2537de7bc6f"
      },
      "source": [
        "smoothing = Flatten()\n",
        "smoothing_f = smoothing.forward(forward_testing)\n",
        "smoothing_b = smoothing.backward(smoothing_f)\n",
        "print(f'Initial---> {forward_testing.shape}')\n",
        "print(f'Forward--> {smoothing_f.shape}')\n",
        "print(f'Backward--> {smoothing_b.shape}')"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Initial---> (20, 3, 28, 28)\n",
            "Forward--> (20, 2352)\n",
            "Backward--> (20, 3, 28, 28)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LcrpDWORqoas"
      },
      "source": [
        "【Problem 6】Smoothing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3J_GevWlqmG_"
      },
      "source": [
        "class FC:\n",
        "\n",
        "    def __init__(self, n_nodes1, n_nodes2, initializer, optimizer):\n",
        "        self.n_nodes1 = n_nodes1\n",
        "        self.n_nodes2 = n_nodes2\n",
        "        self.W = initializer.W(self.n_nodes1, self.n_nodes2)\n",
        "        self.B = initializer.B(self.n_nodes2)\n",
        "        self.optimizer = optimizer\n",
        "        self.HW = 0\n",
        "        self.HB = 0\n",
        "        \n",
        "    def forward(self, X): \n",
        "        self.Z = X\n",
        "        self.A = X @ self.W + self.B\n",
        "        return self.A\n",
        "    \n",
        "    def backward(self, dA):\n",
        "        self.dB = np.sum(dA, axis=0)\n",
        "        self.dW = self.Z.T @ dA\n",
        "        self.dZ = dA @ self.W.T\n",
        "        self = self.optimizer.update(self)\n",
        "        return self.dZ\n",
        "\n",
        "class SoftmaxWithLoss:\n",
        "    \n",
        "    def forward(self, A): \n",
        "        Z = np.exp(A) / np.sum(np.exp(A), axis=1).reshape(-1, 1)\n",
        "        return Z\n",
        "        \n",
        "    def backward(self, Z, y):\n",
        "        dA = Z - y\n",
        "        loss = - np.sum(y * np.log(Z)) / len(y)\n",
        "        return dA, loss\n",
        "    \n",
        "class AdaGrad:\n",
        "\n",
        "    def __init__(self, lr):\n",
        "        self.lr = lr \n",
        "    \n",
        "    def update(self, layer):\n",
        "        layer.HW += layer.dW * layer.dW\n",
        "        layer.HB += layer.dB * layer.dB\n",
        "        delta = 1e-7 \n",
        "        layer.W -= self.lr * layer.dW / (np.sqrt(layer.HW) + delta) / len(layer.Z)\n",
        "        layer.B -= self.lr * layer.dB / (np.sqrt(layer.HB) + delta) / len(layer.Z)\n",
        "        return layer\n",
        "\n",
        "class HeInitializer:\n",
        "\n",
        "    def __init__(self, sigma):\n",
        "        _ = sigma\n",
        "        \n",
        "    def W(self, n_nodes1, n_nodes2):\n",
        "        self.sigma = np.sqrt(2 / n_nodes1)\n",
        "        W = self.sigma * np.random.randn(n_nodes1, n_nodes2)\n",
        "        return W\n",
        "    \n",
        "    def B(self, n_nodes2):\n",
        "        B = self.sigma * np.random.randn(1, n_nodes2)\n",
        "        return B\n",
        "\n",
        "class Relu:\n",
        "\n",
        "    def forward(self, A):\n",
        "        self.A = A\n",
        "        Z = np.maximum(0, A)\n",
        "        return Z\n",
        "    \n",
        "    def backward(self, dZ):\n",
        "        dA = dZ * np.where(self.A > 0, 1, 0)\n",
        "        return dA"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aLA06vN7qr74"
      },
      "source": [
        "class GetMiniBatch:\n",
        "\n",
        "    def __init__(self, X, y, batch_size = 20, seed=0):\n",
        "        self.batch_size = batch_size\n",
        "        np.random.seed(seed)\n",
        "        shuffle_index = np.random.permutation(np.arange(X.shape[0]))\n",
        "        self._X = X[shuffle_index]\n",
        "        self._y = y[shuffle_index]\n",
        "        self._stop = np.ceil(X.shape[0]/self.batch_size).astype(np.int)\n",
        "    def __len__(self):\n",
        "        return self._stop\n",
        "    \n",
        "    def __getitem__(self,item):\n",
        "        p0 = item*self.batch_size\n",
        "        p1 = item*self.batch_size + self.batch_size\n",
        "        return self._X[p0:p1], self._y[p0:p1]  \n",
        "    \n",
        "    def __iter__(self):\n",
        "        self._counter = 0\n",
        "        return self\n",
        "    \n",
        "    def __next__(self):\n",
        "        if self._counter >= self._stop:\n",
        "            raise StopIteration()\n",
        "        p0 = self._counter*self.batch_size\n",
        "        p1 = self._counter*self.batch_size + self.batch_size\n",
        "        self._counter += 1\n",
        "        return self._X[p0:p1], self._y[p0:p1]"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HD0xg2Ioqv_I"
      },
      "source": [
        "def col2im(col, input_shape, filter_h, filter_w, stride=1, pad=0):\n",
        "    N, C, H, W = input_shape\n",
        "    out_h = (H + 2*pad - filter_h)//stride + 1\n",
        "    out_w = (W + 2*pad - filter_w)//stride + 1\n",
        "    col = col.reshape(N, out_h, out_w, C, filter_h, filter_w).transpose(0, 3, 4, 5, 1, 2)\n",
        "\n",
        "    img = np.zeros((N, C, H + 2*pad + stride - 1, W + 2*pad + stride - 1))\n",
        "    for y in range(filter_h):\n",
        "        y_max = y + stride*out_h\n",
        "        for x in range(filter_w):\n",
        "            x_max = x + stride*out_w\n",
        "            img[:, :, y:y_max:stride, x:x_max:stride] += col[:, :, y, x, :, :]\n",
        "\n",
        "    return img[:, :, pad:H + pad, pad:W + pad]"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L1PftEFyqy4m"
      },
      "source": [
        "class MaxPool2D2:\n",
        "\n",
        "    def __init__(self, P_h, P_w, pad=0):\n",
        "        self.P_h = P_h\n",
        "        self.P_w = P_w\n",
        "        self.stride = P_h\n",
        "        self.pad = pad\n",
        "        \n",
        "        self.x = None\n",
        "        self.arg_max = None\n",
        "\n",
        "    def forward(self, x):\n",
        "        N, C, H, W = x.shape\n",
        "        out_h = int(1 + (H - self.P_h) / self.stride)\n",
        "        out_w = int(1 + (W - self.P_w) / self.stride)\n",
        "        col = im2col(x, self.P_h, self.P_w, self.stride, self.pad)\n",
        "        col = col.reshape(-1, self.P_h*self.P_w)\n",
        "        arg_max = np.argmax(col, axis=1)\n",
        "        out = np.max(col, axis=1)\n",
        "        out = out.reshape(N, out_h, out_w, C).transpose(0, 3, 1, 2)\n",
        "        self.x = x\n",
        "        self.arg_max = arg_max\n",
        "        return out\n",
        "\n",
        "    def backward(self, dout):\n",
        "        dout = dout.transpose(0, 2, 3, 1)    \n",
        "        pool_size = self.P_h * self.P_w\n",
        "        dmax = np.zeros((dout.size, pool_size))\n",
        "        dmax[np.arange(self.arg_max.size), self.arg_max.flatten()] = dout.flatten()\n",
        "        dmax = dmax.reshape(dout.shape + (pool_size,))       \n",
        "        dcol = dmax.reshape(dmax.shape[0] * dmax.shape[1] * dmax.shape[2], -1)\n",
        "        dx = col2im(dcol, self.x.shape, self.P_h, self.P_w, self.stride, self.pad)    \n",
        "        return dx"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R6LPOgZ3q1-_"
      },
      "source": [
        "class Scratch2dCNNClassifier:\n",
        "\n",
        "    def __init__(self, FN=20, FH=7, FW=7, stride=1, pad=0, epoch=1, optimizer=AdaGrad, initializer=HeInitializer, activater=Relu, verbose=False,):\n",
        "        self.verbose = verbose\n",
        "        self.batch_size = 60 \n",
        "        self.n_output = 10 \n",
        "        self.sigma = 0.02 \n",
        "        self.lr = 0.05 \n",
        "        self.epoch = epoch \n",
        "        self.optimizer = optimizer \n",
        "        self.initializer = initializer \n",
        "        self.activater = activater \n",
        "        self.FN = FN \n",
        "        self.C = 1 \n",
        "        self.FH = FH \n",
        "        self.FW = FW \n",
        "        self.pool_h = 2 \n",
        "        self.pool_w = 2 \n",
        "        self.pad = pad \n",
        "        self.stride = stride \n",
        "    \n",
        "    def fit(self, X, y, X_val=None, y_val=None):\n",
        "        self.loss_train = [] \n",
        "        self.loss_val = []   \n",
        "        out_h, out_w = self.out_size(28, 28, self.pad, self.FH, self.FW, self.stride)\n",
        "        out_h, out_w = self.out_size(out_h, out_w, 0, self.pool_h, self.pool_w, self.pool_h)\n",
        "        fc_nodes = self.FN * out_h * out_w \n",
        "        optimizer = self.optimizer(self.lr)    \n",
        "        w = self.sigma * np.random.randn(self.FN, self.C, self.FH, self.FW)\n",
        "        b = self.sigma * np.random.randn(self.FN,)\n",
        "        self.cv= SimpleConv2d(self.FN, self.FH, self.FW, self.stride, self.pad, initializer=SimpleInitializer())\n",
        "        self.activation_cv = self.activater()\n",
        "        self.pl = MaxPool2D2(self.pool_h, self.pool_w)\n",
        "        self.fl = Flatten()\n",
        "        self.FC = FC(fc_nodes, self.n_output, self.initializer(self.sigma), optimizer)\n",
        "        self.activation_fc = SoftmaxWithLoss()\n",
        "\n",
        "        for i in range(self.epoch):\n",
        "            get_mini_batch = GetMiniBatch(X, y, batch_size=self.batch_size, seed=i)\n",
        "            for mini_X, mini_y in get_mini_batch:\n",
        "                \n",
        "                A1 = self.cv.forward(mini_X)\n",
        "                Z1 = self.activation_cv.forward(A1)\n",
        "                P1 = self.pl.forward(Z1)\n",
        "                F1 = self.fl.forward(P1)\n",
        "                A2 = self.FC.forward(F1)\n",
        "                Z2 = self.activation_fc.forward(A2)\n",
        "\n",
        "                dA2, loss = self.activation_fc.backward(Z2, mini_y) \n",
        "                dZ2 = self.FC.backward(dA2)\n",
        "                dF1 = self.fl.backward(dZ2)\n",
        "                dP1 = self.pl.backward(dF1)\n",
        "                dA1 = self.activation_cv.backward(dP1)\n",
        "                dZ1 = self.cv.backward(dA1)\n",
        "\n",
        "            if self.verbose:\n",
        "                A1 = self.cv.forward(X)\n",
        "                Z1 = self.activation_cv.forward(A1)\n",
        "                P1 = self.pl.forward(Z1)\n",
        "                F1 = self.fl.forward(P1)\n",
        "                A2 = self.FC.forward(F1)\n",
        "                Z2 = self.activation_fc.forward(A2)  \n",
        "                self.loss_train.append(self.activation_fc.backward(Z2, y)[1])\n",
        "                \n",
        "                if X_val is not None:\n",
        "                    A1 = self.cv.forward(X_val)\n",
        "                    Z1 = self.activation_cv.forward(A1)\n",
        "                    P1 = self.pl.forward(Z1)\n",
        "                    F1 = self.fl.forward(P1)\n",
        "                    A2 = self.FC.forward(F1)\n",
        "                    Z2 = self.activation_fc.forward(A2)         \n",
        "                    self.loss_val.append(self.activation_fc.backward(Z2, y_val)[1])\n",
        "                    \n",
        "    def out_size(self, H, W, P, FH, FW, S):\n",
        "        out_h = (H + 2 * P - FH) // S + 1\n",
        "        out_w = (W + 2 * P - FW) // S + 1\n",
        "        return out_h, out_w\n",
        "    \n",
        "    def predict(self, X):\n",
        "        A1 = self.cv.forward(X)\n",
        "        Z1 = self.activation_cv.forward(A1)\n",
        "        P1 = self.pl.forward(Z1)\n",
        "        F1 = self.fl.forward(P1)\n",
        "        A2 = self.FC.forward(F1)\n",
        "        Z2 = self.activation_fc.forward(A2)\n",
        "        return np.argmax(Z2, axis=1)"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9xIMmUmLq4p2"
      },
      "source": [
        "(X_train2, y_train2), (X_test2, y_test2) = mnist.load_data()\n",
        "\n",
        "X_train2 = X_train2.astype(np.float)\n",
        "X_test2 = X_test2.astype(np.float)\n",
        "X_train2 /= 255 \n",
        "X_test2 /= 255\n",
        "\n",
        "X_train2 = X_train2[:, np.newaxis, :, :] \n",
        "X_test2 = X_test2[:, np.newaxis, :, :]\n",
        "\n",
        "X_train2, X_val2, y_train2, y_val2 = train_test_split(X_train2, y_train2, test_size=0.2)\n",
        "\n",
        "enc = OneHotEncoder(handle_unknown='ignore', sparse=False)\n",
        "y_train_one_hot2 = enc.fit_transform(y_train2[:, np.newaxis])\n",
        "y_test_one_hot2 = enc.transform(y_val2[:, np.newaxis])"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-33Ev6iQrE5Y"
      },
      "source": [
        "S2dCNN = Scratch2dCNNClassifier(FN=5, FH=7, FW=7, stride=1, pad=3, epoch =10, verbose=True)\n",
        "S2dCNN.fit(X_train2, y_train_one_hot2, X_val2, y_test_one_hot2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "heL81NRUrHG5"
      },
      "source": [
        "pred = S2dCNN.predict(X_val2)\n",
        "accuracy_score(y_val2, pred)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}