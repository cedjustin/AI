{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "name": "sprint9.ipynb",
      "provenance": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "ss6CuoXeLwK0"
      },
      "source": [
        "# import the dependencies\n",
        "import numpy as np"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QpVpptBlKKop"
      },
      "source": [
        "#### [Problem 1] Creating a one-dimensional convolutional layer class that limits the number of channels to one"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9VVNhsV2KPw8"
      },
      "source": [
        "class SimpleConv1d():\n",
        "\n",
        "  def forward(self, X, W, b):\n",
        "    a = []\n",
        "    for i in range(len(W)-1):\n",
        "      a.append((np.matmul(X[i:i+len(W)],W))+b[0])\n",
        "    return np.array(a)\n",
        "\n",
        "  def backward(self, X, W, dA):\n",
        "    db = np.sum(dA)\n",
        "    dW = []\n",
        "    for i in range(len(W)):\n",
        "      dW.append(np.matmul(dA,X[i:i+len(dA)]))\n",
        "    dW = np.array(dW)\n",
        "    dX = []\n",
        "    new_W = np.insert(W[::-1],0,0)\n",
        "    new_W = np.append(new_W,0)\n",
        "    for i in range(len(new_W)-1):\n",
        "      dX.append(np.matmul(new_W[i:i+len(dA)],dA))\n",
        "    dX = np.array(dX[::-1])\n",
        "    return db, dW, dX"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_ZxoLZVBOrT3"
      },
      "source": [
        "#### [Problem 2] Output size calculation after one-dimensional convolution"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r_jRj2XUOs9c"
      },
      "source": [
        "def output_size_calc(input_size, f, p=0, s=1):\n",
        "  out_size = ((input_size+2*p-f)/s)+1\n",
        "  return int(out_size)"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AGAWqwK3Pk9G"
      },
      "source": [
        "#### [Problem 3] Experiment of one-dimensional convolutional layer with small array"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dfr7v4gwPn_o"
      },
      "source": [
        "X = np.array([1,2,3,4])\n",
        "W = np.array([3, 5, 7])\n",
        "b = np.array([1])\n",
        "delta_a = np.array([10, 20])"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fc2QiV6vQEJx",
        "outputId": "bca10842-51b5-4ecc-b3e2-99212739ea94"
      },
      "source": [
        "s1dconv = SimpleConv1d()\n",
        "forward_prop = s1dconv.forward(X, W, b)\n",
        "db, dW, dX = s1dconv.backward(X, W, delta_a)\n",
        "print(forward_prop)\n",
        "print(db)\n",
        "print(dW)\n",
        "print(dX)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[35 50]\n",
            "30\n",
            "[ 50  80 110]\n",
            "[ 30 110 170 140]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yk7S_ordR7gN"
      },
      "source": [
        "##### [Problem 4] Creating a one-dimensional convolutional layer class that does not limit the number of channels\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uAigzJvhR-cV"
      },
      "source": [
        "class ConvSimpleInitializer:\n",
        "\n",
        "    def __init__(self, sigma):\n",
        "        self.sigma = sigma\n",
        "        \n",
        "    def W(self, shape):\n",
        "        W = self.sigma * np.random.randn(*shape)\n",
        "        return W\n",
        "    \n",
        "    def b(self, shape):\n",
        "        b = self.sigma * np.random.randn(*shape)\n",
        "        return b"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lPff0xaqVhXi"
      },
      "source": [
        "class ConvSGD:\n",
        "    def __init__(self, lr):\n",
        "        self.lr = lr\n",
        "    def update(self, layer):\n",
        "      layer.W -= self.lr * layer.dW / len(layer.Z)\n",
        "      layer.b -= self.lr * layer.db / len(layer.Z)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fPRxR7aNXXFE"
      },
      "source": [
        "class Adagrad:\n",
        "  def __init__(self,lr):\n",
        "    self.lr = lr\n",
        "    self.hW = 0\n",
        "    self.hb = 0\n",
        "\n",
        "  def update(self, layer):\n",
        "    self.hW += layer.dW*layer.dW\n",
        "    self.hb += layer.db*layer.db\n",
        "    layer.W -= self.lr * layer.dW\n",
        "    layer.b -= self.lr * layer.db\n",
        "    return layer"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hn9xcbnmXons"
      },
      "source": [
        "# mini batch\n",
        "class GetMiniBatch:\n",
        "    \"\"\"\n",
        "Iterator to get a mini-batch\n",
        "    Parameters\n",
        "    ----------\n",
        "    X : The following forms of ndarray, shape (n_samples, n_features)\n",
        "      Training data\n",
        "    y : The following form of ndarray, shape (n_samples, 1)\n",
        "      Correct answer value\n",
        "    batch_size : int\n",
        "      Batch size\n",
        "    seed : int\n",
        "      NumPy random number seed\n",
        "    \"\"\"\n",
        "    def __init__(self, X, y, batch_size = 20, seed=0):\n",
        "        self.batch_size = batch_size\n",
        "        np.random.seed(seed)\n",
        "        shuffle_index = np.random.permutation(np.arange(X.shape[0]))\n",
        "        self._X = X[shuffle_index]\n",
        "        self._y = y[shuffle_index]\n",
        "        self._stop = np.ceil(X.shape[0]/self.batch_size).astype(np.int)\n",
        "    def __len__(self):\n",
        "        return self._stop\n",
        "    def __getitem__(self,item):\n",
        "        p0 = item*self.batch_size\n",
        "        p1 = item*self.batch_size + self.batch_size\n",
        "        return self._X[p0:p1], self._y[p0:p1]        \n",
        "    def __iter__(self):\n",
        "        self._counter = 0\n",
        "        return self\n",
        "    def __next__(self):\n",
        "        if self._counter >= self._stop:\n",
        "            raise StopIteration()\n",
        "        p0 = self._counter*self.batch_size\n",
        "        p1 = self._counter*self.batch_size + self.batch_size\n",
        "        self._counter += 1\n",
        "        return self._X[p0:p1], self._y[p0:p1]"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ieWDGkewYX0v"
      },
      "source": [
        "class Conv1d:\n",
        "  def __init__(self, batch_size, input_size_channel=1, output_size_channel=1, padding=0, initializer, optimizer):\n",
        "    self.batch_size = batch_size\n",
        "    self.input_size_channel = input_size_channel\n",
        "    self.output_size_channel = output_size_channel\n",
        "    self.padding = padding\n",
        "    self.initializer =  initializer\n",
        "    self.optimizer = optimizer\n",
        "    self.W = initializer.W(input_size_channel, output_size_channel, batch_size)\n",
        "    self.b = initializer.b(output_size_channel)\n",
        "    pass\n",
        "\n",
        "  def forward(self, X):\n",
        "    self.input_size = X.shape[-1]\n",
        "    self.output_size = output_size_calc(self.input_size, self.batch_size, self.padding)\n",
        "    X = X.reshape(self.input_size_channel, self.input_size)\n",
        "    self.X = np.pad(X, (0,0),(self.batch_size-1),0)\n",
        "    self.X_1 = np.zeros((self.input_size_channel, self.batch_size, self.input_size + (self.batch_size - 1)))\n",
        "    for i in range(self.batch_size):\n",
        "      self.X_1[:, i] = np.roll(self.X, -i, axis=-1)\n",
        "    A = np.sum(self.X_1[:, :, self.batch_size-1-self.padding:self.input_size + self.padding]self.W[:,:,:,np.newaxis],axis(1,2)+self.b.reshape(-1,1))\n",
        "    return A"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}