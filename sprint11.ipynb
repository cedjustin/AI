{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "name": "sprint9.ipynb",
      "provenance": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "ss6CuoXeLwK0"
      },
      "source": [
        "# import the dependencies\n",
        "import numpy as np"
      ],
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QpVpptBlKKop"
      },
      "source": [
        "#### [Problem 1] Creating a one-dimensional convolutional layer class that limits the number of channels to one"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9VVNhsV2KPw8"
      },
      "source": [
        "class SimpleConv1d():\n",
        "\n",
        "  def forward(self, X, W, b):\n",
        "    a = []\n",
        "    for i in range(len(W)-1):\n",
        "      a.append((np.matmul(X[i:i+len(W)],W))+b[0])\n",
        "    return np.array(a)\n",
        "\n",
        "  def backward(self, X, W, dA):\n",
        "    db = np.sum(dA)\n",
        "    dW = []\n",
        "    for i in range(len(W)):\n",
        "      dW.append(np.matmul(dA,X[i:i+len(dA)]))\n",
        "    dW = np.array(dW)\n",
        "    dX = []\n",
        "    new_W = np.insert(W[::-1],0,0)\n",
        "    new_W = np.append(new_W,0)\n",
        "    for i in range(len(new_W)-1):\n",
        "      dX.append(np.matmul(new_W[i:i+len(dA)],dA))\n",
        "    dX = np.array(dX[::-1])\n",
        "    return db, dW, dX"
      ],
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_ZxoLZVBOrT3"
      },
      "source": [
        "#### [Problem 2] Output size calculation after one-dimensional convolution"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r_jRj2XUOs9c"
      },
      "source": [
        "def output_size_calc(input_size, f, padding=0, stride=1):\n",
        "  out_size = ((input_size+2*padding-f)/stride)+1\n",
        "  return int(out_size)"
      ],
      "execution_count": 103,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AGAWqwK3Pk9G"
      },
      "source": [
        "#### [Problem 3] Experiment of one-dimensional convolutional layer with small array"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dfr7v4gwPn_o"
      },
      "source": [
        "X = np.array([1,2,3,4])\n",
        "W = np.array([3, 5, 7])\n",
        "b = np.array([1])\n",
        "delta_a = np.array([10, 20])"
      ],
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fc2QiV6vQEJx",
        "outputId": "9810b6e8-a6a0-4278-f1fe-7a8f27401835"
      },
      "source": [
        "s1dconv = SimpleConv1d()\n",
        "forward_prop = s1dconv.forward(X, W, b)\n",
        "db, dW, dX = s1dconv.backward(X, W, delta_a)\n",
        "print(forward_prop)\n",
        "print(db)\n",
        "print(dW)\n",
        "print(dX)"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[35 50]\n",
            "30\n",
            "[ 50  80 110]\n",
            "[ 30 110 170 140]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yk7S_ordR7gN"
      },
      "source": [
        "##### [Problem 4], [Problem 5], [Problem 6]\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uAigzJvhR-cV"
      },
      "source": [
        "class SimpleInitializer:\n",
        "\n",
        "    def __init__(self, sigma):\n",
        "        self.sigma = sigma\n",
        "        \n",
        "    def W(self, *shape):\n",
        "        W = self.sigma * np.random.randn(*shape)\n",
        "        return W\n",
        "    \n",
        "    def b(self, *shape):\n",
        "        b = self.sigma * np.random.randn(*shape)\n",
        "        return b"
      ],
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lPff0xaqVhXi"
      },
      "source": [
        "class SGD:\n",
        "    def __init__(self, lr):\n",
        "        self.lr = lr\n",
        "    def update(self, layer):\n",
        "        layer.W -= self.lr * layer.dW / len(layer.Z)\n",
        "        layer.b -= self.lr * layer.dB / len(layer.Z)\n",
        "        return layer"
      ],
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fPRxR7aNXXFE"
      },
      "source": [
        "class Adagrad:\n",
        "  def __init__(self,lr):\n",
        "    self.lr = lr\n",
        "    self.hW = 0\n",
        "    self.hb = 0\n",
        "\n",
        "  def update(self, layer):\n",
        "    self.hW += layer.dW*layer.dW\n",
        "    self.hb += layer.db*layer.db\n",
        "    layer.W -= self.lr * layer.dW\n",
        "    layer.b -= self.lr * layer.db\n",
        "    return layer"
      ],
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hn9xcbnmXons"
      },
      "source": [
        "# mini batch\n",
        "class GetMiniBatch:\n",
        "    \"\"\"\n",
        "Iterator to get a mini-batch\n",
        "    Parameters\n",
        "    ----------\n",
        "    X : The following forms of ndarray, shape (n_samples, n_features)\n",
        "      Training data\n",
        "    y : The following form of ndarray, shape (n_samples, 1)\n",
        "      Correct answer value\n",
        "    batch_size : int\n",
        "      Batch size\n",
        "    seed : int\n",
        "      NumPy random number seed\n",
        "    \"\"\"\n",
        "    def __init__(self, X, y, batch_size = 20, seed=0):\n",
        "        self.batch_size = batch_size\n",
        "        np.random.seed(seed)\n",
        "        shuffle_index = np.random.permutation(np.arange(X.shape[0]))\n",
        "        self._X = X[shuffle_index]\n",
        "        self._y = y[shuffle_index]\n",
        "        self._stop = np.ceil(X.shape[0]/self.batch_size).astype(np.int)\n",
        "    def __len__(self):\n",
        "        return self._stop\n",
        "    def __getitem__(self,item):\n",
        "        p0 = item*self.batch_size\n",
        "        p1 = item*self.batch_size + self.batch_size\n",
        "        return self._X[p0:p1], self._y[p0:p1]        \n",
        "    def __iter__(self):\n",
        "        self._counter = 0\n",
        "        return self\n",
        "    def __next__(self):\n",
        "        if self._counter >= self._stop:\n",
        "            raise StopIteration()\n",
        "        p0 = self._counter*self.batch_size\n",
        "        p1 = self._counter*self.batch_size + self.batch_size\n",
        "        self._counter += 1\n",
        "        return self._X[p0:p1], self._y[p0:p1]"
      ],
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ieWDGkewYX0v"
      },
      "source": [
        "class Conv1d:\n",
        "  def __init__(self, batch_size, initializer, optimizer, input_size_channel=1, output_size_channel=1, padding=0):\n",
        "    self.batch_size = batch_size\n",
        "    self.input_size_channel = input_size_channel\n",
        "    self.output_size_channel = output_size_channel\n",
        "    self.padding = padding\n",
        "    self.initializer =  initializer\n",
        "    self.optimizer = optimizer\n",
        "    self.W = initializer.W(input_size_channel, output_size_channel, batch_size)\n",
        "    self.b = initializer.b(output_size_channel)\n",
        "\n",
        "  def forward(self, X):\n",
        "    self.n_in = X.shape[-1]\n",
        "    self.n_out = output_size_calc(self.n_in, self.batch_size, self.padding)\n",
        "    X = X.reshape(self.input_size_channel, self.n_in)\n",
        "    self.X = np.pad(X, ((0,0), ((self.batch_size-1), 0)))\n",
        "    self.X1 = np.zeros((self.input_size_channel, self.batch_size, self.n_in+(self.batch_size-1)))\n",
        "    for i in range(self.batch_size):\n",
        "        self.X1[:, i] = np.roll(self.X, -i, axis=-1)\n",
        "    A = np.sum(self.X1[:, :, self.batch_size-1-self.padding:self.n_in+self.padding]*self.W[:, :, :, np.newaxis], axis=(1, 2)) + self.b.reshape(-1,1)\n",
        "    return A\n",
        "\n",
        "  def backward(self, dA):\n",
        "    self.dW = np.sum(np.dot(dA, self.X1[:, :, self.batch_size-1-self.padding:self.input_size+self.padding, np.newaxis]), axis=-1)\n",
        "    self.dB = np.sum(dA, axis=1)\n",
        "    self.dA = np.pad(dA, ((0,0), (0, (self.batch_size-1))))\n",
        "    self.dA1 = np.zeros((self.output_size_channel, self.batch_size, self.dA.shape[-1]))\n",
        "    for i in range(self.batch_size):\n",
        "        self.dA1[:, i] = np.roll(self.dA, i, axis=-1)\n",
        "    dX = np.sum(self.W@self.dA1, axis=0)\n",
        "    self.optimizer.update(self)\n",
        "    return dX"
      ],
      "execution_count": 108,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1d7ESqekbgOA"
      },
      "source": [
        "model_1 = Conv1d(3, SimpleInitializer(0.01), SGD(0.01), 2, 3, 0)"
      ],
      "execution_count": 109,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LChMEuhkdpi-",
        "outputId": "ef33688d-8b62-4446-cd49-ae9c08db5718",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "x = np.array([[1, 2, 3, 4], [2, 3, 4, 5]]) \n",
        "model_1.W = np.ones((3, 2, 3), dtype=float)\n",
        "model_1.b = np.array([1, 2, 3], dtype=float)\n",
        "model_1_forward = model_1.forward(x)\n",
        "model_1_forward"
      ],
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[16., 22.],\n",
              "       [17., 23.],\n",
              "       [18., 24.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 110
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UAD9m8HNmlVc"
      },
      "source": [
        "#### [Problem 7] (Advance assignment) Arbitrary number of strides"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QNscJEPamiPP"
      },
      "source": [
        "class AdvConv1d:\n",
        "  def __init__(self, batch_size, initializer, optimizer, input_size_channel=1, output_size_channel=1, padding=0, stride=1):\n",
        "    self.batch_size = batch_size\n",
        "    self.input_size_channel = input_size_channel\n",
        "    self.output_size_channel = output_size_channel\n",
        "    self.padding = padding\n",
        "    self.stride = stride\n",
        "    self.initializer =  initializer\n",
        "    self.optimizer = optimizer\n",
        "    self.W = initializer.W(input_size_channel, output_size_channel, batch_size)\n",
        "    self.b = initializer.b(output_size_channel)\n",
        "\n",
        "  def forward(self, X):\n",
        "    self.n_in = X.shape[-1]\n",
        "    self.n_out = output_size_calc(self.n_in, self.batch_size, self.padding, self.stride)\n",
        "    X = X.reshape(self.input_size_channel, self.n_in)\n",
        "    self.X = np.pad(X, ((0,0), ((self.batch_size-1), 0)))\n",
        "    self.X1 = np.zeros((self.input_size_channel, self.batch_size, self.n_in+(self.batch_size-1)))\n",
        "    for i in range(self.batch_size):\n",
        "        self.X1[:, i] = np.roll(self.X, -i, axis=-1)\n",
        "    A = np.sum(self.X1[:, :, self.batch_size-1-self.padding:self.n_in+self.padding:self.stride]*self.W[:, :, :, np.newaxis], axis=(1, 2)) + self.B.reshape(-1,1)\n",
        "    return A\n",
        "\n",
        "  def backward(self, dA):\n",
        "    self.dW = np.sum(np.dot(dA, self.X1[:, :, self.batch_size-1-self.padding:self.input_size+self.padding:self.stride, np.newaxis]), axis=-1)\n",
        "    self.dB = np.sum(dA, axis=1)\n",
        "    self.dA = np.pad(dA, ((0,0), (0, (self.batch_size-1))))\n",
        "    self.dA1 = np.zeros((self.output_size_channel, self.batch_size, self.dA.shape[-1]))\n",
        "    for i in range(self.batch_size):\n",
        "        self.dA1[:, i] = np.roll(self.dA, i, axis=-1)\n",
        "    dX = np.sum(self.W@self.dA1, axis=0)\n",
        "    self.optimizer.update(self)\n",
        "    return dX"
      ],
      "execution_count": 105,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q-8d6zUhng1a",
        "outputId": "bcd8a170-838d-4979-9042-772f79d550ec",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model_2 = AdvConv1d(3, SimpleInitializer(0.01), SGD(0.01), 2, 3, 0, 2)\n",
        "x = np.array([[1, 2, 3, 4], [2, 3, 4, 5]]) \n",
        "model_2.W = np.ones((3, 2, 3), dtype=float)\n",
        "model_2.b = np.array([1, 2, 3], dtype=float)\n",
        "model_2_forward = model_1.forward(x)\n",
        "model_2_forward"
      ],
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[16., 22.],\n",
              "       [17., 23.],\n",
              "       [18., 24.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 113
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TAPWT0sboDcM"
      },
      "source": [
        "#### [Problem 8] Learning and estimation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WTJ_39vkoIRx"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}