{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing dependencies\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>OverallQual</th>\n",
       "      <th>OverallCond</th>\n",
       "      <th>YearBuilt</th>\n",
       "      <th>YearRemodAdd</th>\n",
       "      <th>MasVnrArea</th>\n",
       "      <th>BsmtFinSF1</th>\n",
       "      <th>...</th>\n",
       "      <th>WoodDeckSF</th>\n",
       "      <th>OpenPorchSF</th>\n",
       "      <th>EnclosedPorch</th>\n",
       "      <th>3SsnPorch</th>\n",
       "      <th>ScreenPorch</th>\n",
       "      <th>PoolArea</th>\n",
       "      <th>MiscVal</th>\n",
       "      <th>MoSold</th>\n",
       "      <th>YrSold</th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>65.0</td>\n",
       "      <td>8450</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>2003</td>\n",
       "      <td>2003</td>\n",
       "      <td>196.0</td>\n",
       "      <td>706</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>61</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2008</td>\n",
       "      <td>208500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>80.0</td>\n",
       "      <td>9600</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>1976</td>\n",
       "      <td>1976</td>\n",
       "      <td>0.0</td>\n",
       "      <td>978</td>\n",
       "      <td>...</td>\n",
       "      <td>298</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2007</td>\n",
       "      <td>181500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>60</td>\n",
       "      <td>68.0</td>\n",
       "      <td>11250</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>2001</td>\n",
       "      <td>2002</td>\n",
       "      <td>162.0</td>\n",
       "      <td>486</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>42</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>2008</td>\n",
       "      <td>223500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>70</td>\n",
       "      <td>60.0</td>\n",
       "      <td>9550</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>1915</td>\n",
       "      <td>1970</td>\n",
       "      <td>0.0</td>\n",
       "      <td>216</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>272</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2006</td>\n",
       "      <td>140000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>60</td>\n",
       "      <td>84.0</td>\n",
       "      <td>14260</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>2000</td>\n",
       "      <td>2000</td>\n",
       "      <td>350.0</td>\n",
       "      <td>655</td>\n",
       "      <td>...</td>\n",
       "      <td>192</td>\n",
       "      <td>84</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>2008</td>\n",
       "      <td>250000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 38 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id  MSSubClass  LotFrontage  LotArea  OverallQual  OverallCond  YearBuilt  \\\n",
       "0   1          60         65.0     8450            7            5       2003   \n",
       "1   2          20         80.0     9600            6            8       1976   \n",
       "2   3          60         68.0    11250            7            5       2001   \n",
       "3   4          70         60.0     9550            7            5       1915   \n",
       "4   5          60         84.0    14260            8            5       2000   \n",
       "\n",
       "   YearRemodAdd  MasVnrArea  BsmtFinSF1  ...  WoodDeckSF  OpenPorchSF  \\\n",
       "0          2003       196.0         706  ...           0           61   \n",
       "1          1976         0.0         978  ...         298            0   \n",
       "2          2002       162.0         486  ...           0           42   \n",
       "3          1970         0.0         216  ...           0           35   \n",
       "4          2000       350.0         655  ...         192           84   \n",
       "\n",
       "   EnclosedPorch  3SsnPorch  ScreenPorch  PoolArea  MiscVal  MoSold  YrSold  \\\n",
       "0              0          0            0         0        0       2    2008   \n",
       "1              0          0            0         0        0       5    2007   \n",
       "2              0          0            0         0        0       9    2008   \n",
       "3            272          0            0         0        0       2    2006   \n",
       "4              0          0            0         0        0      12    2008   \n",
       "\n",
       "   SalePrice  \n",
       "0     208500  \n",
       "1     181500  \n",
       "2     223500  \n",
       "3     140000  \n",
       "4     250000  \n",
       "\n",
       "[5 rows x 38 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# importing dataset\n",
    "data=pd.read_csv('train.csv').select_dtypes(include='number')\n",
    "\n",
    "# handling of missing values\n",
    "data.isnull().sum()\n",
    "data = data.fillna(data.mean())\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape:(1460, 37), y shape:(1460,)\n"
     ]
    }
   ],
   "source": [
    "# splitting the data\n",
    "X = data.drop(['SalePrice'],axis=1).values\n",
    "y = data['SalePrice'].values\n",
    "\n",
    "X = np.log1p(X)\n",
    "y = np.log1p(y)\n",
    "\n",
    "print('X shape:{}, y shape:{}'.format(X.shape,y.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Problem 1] Blending scratch mounting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape:(1168, 37), y_test shape:(292,)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2,random_state=1)\n",
    "print('X_train shape:{}, y_test shape:{}'.format(X_train.shape,y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE\n",
      "-------\n",
      "blend:0.025\n"
     ]
    }
   ],
   "source": [
    "# example 1\n",
    "models = [LinearRegression(),SVR(),DecisionTreeRegressor()]\n",
    "predictions = list()\n",
    "for model in models:\n",
    "    model.fit(X_train,y_train)\n",
    "    predictions.append(model.predict(X_test))\n",
    "    \n",
    "predictions_ndarray = np.array(predictions)\n",
    "blend = np.mean(predictions_ndarray,axis=0)\n",
    "\n",
    "print('MSE')\n",
    "print('-------')\n",
    "print('blend:{:.3f}'.format(mean_squared_error(y_test,blend)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE\n",
      "-------\n",
      "blend:0.023\n"
     ]
    }
   ],
   "source": [
    "# example 2\n",
    "svr_model1 = SVR(C=1)\n",
    "svr_model2 = SVR(C=5)\n",
    "svr_model3 = SVR(C=10)\n",
    "svr_model1.fit(X_train,y_train)\n",
    "svr_model2.fit(X_train,y_train)\n",
    "svr_model3.fit(X_train,y_train)\n",
    "svr_pred1 = svr_model1.predict(X_test)\n",
    "svr_pred2 = svr_model2.predict(X_test)\n",
    "svr_pred3 = svr_model2.predict(X_test)\n",
    "    \n",
    "svr_blend = np.mean([svr_pred1,svr_pred2,svr_pred3],axis=0)\n",
    "\n",
    "print('MSE')\n",
    "print('-------')\n",
    "print('blend:{:.3f}'.format(mean_squared_error(y_test,svr_blend)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE\n",
      "-------\n",
      "blend:0.025\n"
     ]
    }
   ],
   "source": [
    "# example 3\n",
    "std_scaler = StandardScaler()\n",
    "std_scaler.fit(X_train)\n",
    "X_train_trans = std_scaler.transform(X_train)\n",
    "X_test_trans = std_scaler.transform(X_test)\n",
    "\n",
    "models2 = [LinearRegression(),SVR(),DecisionTreeRegressor()]\n",
    "predictions2 = list()\n",
    "for model in models2:\n",
    "    model.fit(X_train_trans,y_train)\n",
    "    predictions2.append(model.predict(X_test_trans))\n",
    "    \n",
    "predictions_ndarray2 = np.array(predictions)\n",
    "blend2 = np.mean(predictions_ndarray2,axis=0)\n",
    "\n",
    "print('MSE')\n",
    "print('-------')\n",
    "print('blend:{:.3f}'.format(mean_squared_error(y_test,blend2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Problem 2] Scratch mounting of bagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape:(1168, 37), y_test shape:(292,)\n"
     ]
    }
   ],
   "source": [
    "X_train_bag, X_test_bag, y_train_bag, y_test_bag = train_test_split(X,y,test_size=0.2,shuffle=True)\n",
    "print('X_train shape:{}, y_test shape:{}'.format(X_train_bag.shape,y_test_bag.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average of bagging pred:[12.25781018 11.99545486 11.56490218 11.01704575 11.94186951 12.60472669\n",
      " 12.58042908 11.86406303 12.27052756 12.36113397 12.0939682  11.00131567\n",
      " 12.18649386 12.48819131 12.34279943 11.62444362 11.62101697 11.72839201\n",
      " 12.32107768 11.77422308 11.66586087 11.71891534 12.48142256 12.65000953\n",
      " 11.47600934 12.20612542 11.72834793 12.16375025 12.86618536 11.83589528\n",
      " 11.74874805 11.68659899 11.65633567 11.49411183 11.90581371 12.73189308\n",
      " 11.77319291 11.28173979 12.60565707 11.64456544 11.89372723 11.92868525\n",
      " 11.53293091 11.74298774 12.13173827 12.08552396 11.73163762 12.06724842\n",
      " 12.41677083 12.37049595 11.51794257 12.66519841 11.50253555 12.34734819\n",
      " 12.25089831 11.51290754 11.68953193 12.03161852 11.74564378 12.13721745\n",
      " 12.05648355 12.55936264 11.48373346 11.57012425 12.03181347 11.78683765\n",
      " 11.75998572 12.3373183  12.07654313 11.93577139 11.98668656 11.49884952\n",
      " 12.64776829 11.95045468 12.01314801 12.27184901 12.04960477 11.86340477\n",
      " 12.89247505 12.22241589 12.2218487  11.75390128 11.79758841 12.00855168\n",
      " 12.19222809 12.02820085 12.00452348 12.02568851 12.14031919 12.08525063\n",
      " 12.20024787 11.98374621 11.59182636 11.49854593 11.79144265 11.75484805\n",
      " 11.66828866 11.80456354 11.94793314 11.88906072 11.98585921 11.81101929\n",
      " 11.63764146 11.64858042 11.79048556 12.13395466 12.11081098 12.13542959\n",
      " 11.92171686 12.68637318 11.92443487 12.09030299 11.90105268 12.16977428\n",
      " 12.36422607 12.04217245 12.30038176 11.75944756 12.05778526 12.50073588\n",
      " 11.87475675 12.29733837 12.74241422 11.95535723 12.08302274 12.14328756\n",
      " 12.60499457 11.64641506 12.22847787 12.27880864 12.53297105 11.41171568\n",
      " 11.76197399 11.80757526 11.47063079 12.22388777 12.72587822 12.66876231\n",
      " 12.41268457 11.85316862 11.76352232 12.54425055 12.15202436 12.16215767\n",
      " 11.53200446 12.12776861 11.49762479 12.15141199 12.34359973 11.60348324\n",
      " 12.12636599 12.02402545 11.69002493 12.11512468 12.17955682 12.62426532\n",
      " 11.24559369 11.84295218 11.33126345 11.80387283 10.83409738 11.49062511\n",
      " 11.90795891 11.88615261 11.62666707 11.79329666 11.98271453 11.83334174\n",
      " 11.89244882 11.56269796 12.35661599 11.87206539 12.31573002 12.53100769\n",
      " 12.22329101 11.81543566 12.21781183 12.1905919  11.82887715 12.0558039\n",
      " 11.8343862  12.06805951 11.91456029 11.89133242 12.55767453 11.84760809\n",
      " 12.5735829  12.59249117 12.05836336 11.70744783 11.53627764 11.8841952\n",
      " 11.489222   12.24655159 11.77933798 12.50995396 12.32708747 11.95063796\n",
      " 11.90384482 11.03802792 12.23432108 12.34975594 12.10713942 12.03979855\n",
      " 12.43058494 11.70484107 12.14260578 12.61928926 12.39397228 12.36948621\n",
      " 12.1980879  11.64350693 11.97702499 11.6939772  12.57630428 12.44839643\n",
      " 11.70891099 11.37884673 12.25849631 11.13916403 13.00202785 11.68743647\n",
      " 11.93568418 12.21364068 11.69613085 11.72352883 12.16703848 12.0550451\n",
      " 11.94046769 12.02636426 11.70174296 12.09797776 11.5081532  11.79550974\n",
      " 12.63196877 11.67891512 12.58246759 11.66545513 11.79075479 12.59379485\n",
      " 12.7708529  11.87258673 11.8602322  11.87056142 11.82723683 11.63965374\n",
      " 11.96200222 11.91823821 11.99550024 12.00096934 11.63564484 11.58921417\n",
      " 12.09134308 12.08235329 11.6225595  11.66887091 12.14538924 11.2683327\n",
      " 12.62561781 11.75866171 12.22218686 12.14052999 12.27384959 12.06339638\n",
      " 11.61199633 12.25228018 11.77071536 12.12709153 11.92061986 11.4934439\n",
      " 12.12482482 12.11111709 11.38813463 11.64913052 12.11537418 11.40596943\n",
      " 11.66630664 11.8033653  11.95899572 11.87251728 11.84049191 11.82417407\n",
      " 11.77505609 11.90792659 12.37112628 12.41784365 11.71135554 11.38274938\n",
      " 12.34071641 11.54463024 11.37364782 12.51356676]\n",
      "average of bagging pred:0.034030759934420306\n"
     ]
    }
   ],
   "source": [
    "models = [LinearRegression(),SVR(),DecisionTreeRegressor()]\n",
    "# predictions = list()\n",
    "# for model in models:\n",
    "#     model.fit(X_train_bag,y_train_bag)\n",
    "#     predictions.append(model.predict(X_test_bag))\n",
    "    \n",
    "# predictions_ndarray = np.array(predictions)\n",
    "# blend = np.mean(predictions_ndarray,axis=0)\n",
    "\n",
    "# print('MSE')\n",
    "# print('-------')\n",
    "# print('blend:{:.3f}'.format(mean_squared_error(y_test_bag,blend)))\n",
    "class BaggingScratch():\n",
    "    def __init__(self, models):\n",
    "        self.models = models\n",
    "        self.predictions = list()\n",
    "        self.mses = list()\n",
    "        \n",
    "    def fit(self,X,y):\n",
    "        for model in models:\n",
    "            model.fit(X,y)\n",
    "    def predict(self,X,y):\n",
    "        for model in self.models:\n",
    "            prediction = model.predict(X)\n",
    "            self.predictions.append(prediction)\n",
    "            self.mses.append(mean_squared_error(y,prediction))\n",
    "        return np.mean(np.array(self.predictions),axis=0)\n",
    "    def mse(self):\n",
    "        mses_ndarray = np.array(self.mses)\n",
    "        return np.mean(mses_ndarray,axis=0)\n",
    "    \n",
    "\n",
    "bag = BaggingScratch(models)\n",
    "bag.fit(X_train,y_train)\n",
    "print(\"average of bagging pred:{}\".format(bag.predict(X_test,y_test)))\n",
    "print(\"average of bagging pred:{}\".format(bag.mse()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Problem 3] Stacking scratch mounting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset():\n",
    "    X, y = datasets.make_classification(n_samples=10000, n_features=20, n_informative=15, n_redundant=5, random_state=7)\n",
    "    return X, y\n",
    "\n",
    "X, y = get_dataset()\n",
    "# splitting into train and tests(used for base models)\n",
    "X_train_full, X_test_1, y_train_full, y_test_1 = train_test_split(X,y,test_size=0.5,random_state=1)\n",
    "\n",
    "# splitting into train and validations(used for ensemble model)\n",
    "X_train_1, X_val, y_train_1, y_val = train_test_split(X_train_full,y_train_full,test_size=0.2,random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a function to return the models in a form of a tuple\n",
    "def get_models():\n",
    "    models = list()\n",
    "    models.append(('lr',LinearRegression()))\n",
    "    models.append(('knn', KNeighborsClassifier()))\n",
    "    models.append(('cart', DecisionTreeRegressor()))\n",
    "    models.append(('bayes', GaussianNB()))\n",
    "    return models\n",
    "\n",
    "# a function to fit and blend all of our models\n",
    "def fit_ensemble(models, X_train_1, X_val, y_train_1, y_val):\n",
    "    # fit and predict using the validation data\n",
    "    \n",
    "    # a list to hold the predicted data from the base model for the blender model\n",
    "    meta_X = list()\n",
    "    \n",
    "    # loop through our models\n",
    "    for name,model in models:\n",
    "        model.fit(X_train_1, y_train_1)\n",
    "        y_pred = model.predict(X_val)\n",
    "        \n",
    "        # reshaping the predicted results into a matrix with one column\n",
    "        y_pred = y_pred.reshape(len(y_pred), 1)\n",
    "        meta_X.append(y_pred)\n",
    "        \n",
    "    meta_X = np.hstack(meta_X)\n",
    "    \n",
    "    # defining our blender\n",
    "    blender = LinearRegression()\n",
    "    \n",
    "    # fitting our blender using our meta values and y validation set\n",
    "    blender.fit(meta_X, y_val)\n",
    "    return blender\n",
    "\n",
    "# a function to make predictions with our ensemble\n",
    "def pred_ensemble(models, blender, X_test_1):\n",
    "    # a list to hold te predictions for the blender\n",
    "    meta_X = list()\n",
    "    \n",
    "    # loop through our models\n",
    "    for name,model in models:\n",
    "        \n",
    "        # predicting using our base models\n",
    "        y_pred = model.predict(X_test_1)\n",
    "        \n",
    "        # reshaping the predicted results into a matrix with one column\n",
    "        y_pred = y_pred.reshape(len(y_pred), 1)\n",
    "        meta_X.append(y_pred)\n",
    "        \n",
    "    meta_X = np.hstack(meta_X)\n",
    "    \n",
    "    # predicting using our blender\n",
    "    return blender.predict(meta_X)\n",
    "\n",
    "models = get_models()\n",
    "blender = fit_ensemble(models, X_train_1, X_val, y_train_1, y_val)\n",
    "y_pred = pred_ensemble(models, blender, X_test_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values used\n",
      "Train:(4000, 20) Val:(1000, 20) Test:(5000, 20)\n",
      "Accuracy score\n",
      "------------------\n",
      "Blended ensemble:0.023\n",
      "Logistic regression:0.110\n"
     ]
    }
   ],
   "source": [
    "# printing mse\n",
    "print(\"Values used\")\n",
    "print(\"Train:{} Val:{} Test:{}\".format(X_train_1.shape, X_val.shape, X_test_1.shape))\n",
    "print(\"Accuracy score\")\n",
    "print(\"------------------\")\n",
    "print(\"Blended ensemble:{:.3f}\".format(mean_squared_error(y_test_1,y_pred)))\n",
    "\n",
    "# on individual model\n",
    "model = LinearRegression()\n",
    "model.fit(X_train_1, y_train_1)\n",
    "y_pred1= model.predict(X_test_1)\n",
    "print(\"Logistic regression:{:.3f}\".format(mean_squared_error(y_test_1,y_pred1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
